{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "import math\n",
    "from email import policy\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict\n",
    "\n",
    "class SpamNaiveBayes:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    \n",
    "    # treina o modelo\n",
    "    def fit(self, files, labels):\n",
    "        self.spam = defaultdict(int)\n",
    "        self.ham = defaultdict(int)\n",
    "        self.total_words = self.spam_words = self.ham_words = 0\n",
    "        for file in files:\n",
    "            body = self.read_email(file)\n",
    "            words = body.split()\n",
    "            for word in words:      \n",
    "                if labels[file] == 0:\n",
    "                    if word in self.spam:\n",
    "                        self.spam[word] += 1\n",
    "                    else:\n",
    "                        self.spam[word] = 1\n",
    "                else:\n",
    "                    if word in self.ham:\n",
    "                        self.ham[word] += 1\n",
    "                    else:\n",
    "                        self.ham[word] = 1\n",
    "        self.spam_words = sum(self.spam.values())\n",
    "        self.ham_words = sum(self.ham.values())\n",
    "        self.total_words = self.spam_words + self.ham_words\n",
    "    \n",
    "    # faz a previsão de um novo email\n",
    "    def predict(self, file, labels, k=1):\n",
    "        body = self.read_email(file)\n",
    "        words = body.split()\n",
    "        spam_prob = math.log(self.spam_words / self.total_words)\n",
    "        ham_prob = math.log(self.ham_words / self.total_words)\n",
    "        for word in words:\n",
    "            spam_prob += math.log((self.spam[word] + k) / (self.spam_words + k*2))\n",
    "            ham_prob += math.log((self.ham[word] + k) / (self.ham_words + k*2))\n",
    "    \n",
    "        return int(ham_prob > spam_prob)\n",
    "    \n",
    "    # avalia o modelo a partir de um conjunto de dados e uma função de validação\n",
    "    def test(self, files, labels, k=1, function='accuracy'):\n",
    "        right_prev = tp = tn = fp = fn = 0\n",
    "        for file in files:\n",
    "            prev = self.predict(file, labels, k)\n",
    "            if prev == labels[file]:\n",
    "                right_prev += 1\n",
    "                if prev == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "            else:\n",
    "                if prev == 1:\n",
    "                    fp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "        if function == 'precision':\n",
    "            return tp / (tp + fp)\n",
    "        if function == 'recall':\n",
    "            return tp / (tp + fn)\n",
    "        return right_prev / len(files)\n",
    "        \n",
    "    # faz o tratamento da leitura do email\n",
    "    def read_email(self, file):\n",
    "        fin = open(self.path + file, encoding='ISO-8859-1')\n",
    "        mail = email.message_from_file(fin, policy=policy.default)\n",
    "        body = \"\"\n",
    "        if mail.is_multipart():\n",
    "            for part in mail.walk():\n",
    "                ctype = part.get_content_type()\n",
    "                cdispo = str(part.get('Content-Disposition'))\n",
    "                if ctype == 'text/plain' and 'attachment' not in cdispo:\n",
    "                    body = part.get_payload()\n",
    "                    break\n",
    "        else:\n",
    "            body = mail.get_payload()\n",
    "        return body\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(files, split=0.20):\n",
    "    sample = int(split * len(files))\n",
    "    return files[sample:], files[0:sample]\n",
    "\n",
    "def cross_validation(path, files, labels, k_values, n, function='accuracy'):    \n",
    "    ps = int(len(files) / n)\n",
    "    best_model = None\n",
    "    best_value = 0\n",
    "    for k in k_values:\n",
    "        snb = SpamNaiveBayes(path)\n",
    "        total_values = 0\n",
    "        for i in range(0, len(files), ps):\n",
    "            train, validation = files[0:i] + files[i+ps:], files[i:i+ps]\n",
    "            if len(validation) == ps:\n",
    "                snb.fit(train, labels)\n",
    "                total_values += snb.test(validation, labels, k, function)\n",
    "                \n",
    "        mean = total_values / n\n",
    "        print('k =', k, function, '=', mean)\n",
    "        if mean > best_value:\n",
    "            best_value = mean\n",
    "            best_model = snb\n",
    "            \n",
    "    return best_model, best_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0.01 accuracy = 0.9771676300578035\n",
      "k = 0.04 accuracy = 0.9777456647398843\n",
      "k = 0.07 accuracy = 0.9774566473988437\n",
      "k = 0.1 accuracy = 0.9771676300578033\n",
      "k = 0.4 accuracy = 0.9745664739884393\n",
      "k = 0.7 accuracy = 0.9739884393063584\n",
      "k = 1 accuracy = 0.972543352601156\n",
      "Cross validation accuracy: 0.9777456647398843\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "\n",
    "label_file = open('./SPAM-DATA/SPAMTrain.label')\n",
    "for row in label_file:\n",
    "    label, file = row.strip().split()    \n",
    "    labels[file] = int(label)\n",
    "\n",
    "path = './SPAM-DATA/DATA/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "train_mails, test_mails = train_test_split(files)\n",
    "\n",
    "k_values = [0.01, 0.04, 0.07, 0.1, 0.4, 0.7, 1]\n",
    "SpamNB, best_k = cross_validation(path, train_mails, labels, k_values=k_values, n=10)\n",
    "print('Cross validation accuracy:', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9710982658959537\n",
      "Precision: 0.976027397260274\n",
      "Recall: 0.9810671256454389\n",
      "                 Predita Positiva    Predita Negativa\n",
      "-------------  ------------------  ------------------\n",
      "Real Positva                  570                  11\n",
      "Real Negativa                  14                 270\n"
     ]
    }
   ],
   "source": [
    "right_prev = tp = tn = fp = fn = 0\n",
    "for file in test_mails:\n",
    "    prev = SpamNB.predict(file, labels, best_k)\n",
    "    if prev == labels[file]:\n",
    "        right_prev += 1\n",
    "        if prev == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    else:\n",
    "        if prev == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "accuracy = right_prev / len(test_mails)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print(tabulate([['Real Positva', tp, fn], ['Real Negativa', fp, tn]], headers=['', 'Predita Positiva', 'Predita Negativa']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
